# MySQL中的行锁

什么是行锁？

- 行锁由引擎层中的各个**引擎自己实现的**。**并不是所有的引擎都支持行锁**，比如MyISAM就不支持行锁。因此，不支持行锁的引擎只能通过表锁来实现并发控制，但这会影响业务并发度。因为在表锁的并发控制下，同一张表上任何时刻只能有一个更新在执行。
- **行锁是指对数据表中的行记录加锁。**



## 两阶段锁

**在InnoDB事务中，行锁是在需要的时候才加上的，行锁需要等事务结束后才能释放。这就是两阶段锁协议。**

如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发的锁尽量往后放。示例：

假设你负责实现一个电影票在线交易业务，顾客 A 要在影院 B 购买电影票。我们简化一点，这个业务需要涉及到以下操作：

1. 从顾客 A 账户余额中扣除电影票价；

2. 给影院 B 的账户余额增加这张电影票价；

3. 记录一条交易日志。

也就是说，要完成这个交易，我们需要 update 两条记录，并 insert 一条记录。当然，为了保证交易的原子性，我们要把这三个操作放在一个事务中。那么，你会怎样安排这三个语句在事务中的顺序呢？

试想如果同时有另外一个顾客 C 要在影院 B  买票，那么这两个事务冲突的部分就是语句 2  了。因为它们要更新同一个影院账户的余额，需要修改同一行数据。

根据两阶段锁协议，不论你怎样安排语句顺序，所有的操作需要的行锁都是在事务提交的时候才释放的。所以，如果你把语句 2 安排在最后，比如按照 3、1、2 这样的顺序，那么影院账户余额这一行的锁时间就最少。这就最大程度地减少了事务之间的锁等待，提升了并发度。



如果这个影院做活动，可以低价预售一年内所有的电影票，而且这个活动只做一天。于是在活动时间开始的时候，你的 MySQL 就挂了。你登上服务器一看，CPU 消耗接近 100%，但整个数据库每秒就执行不到 100 个事务。这是什么原因呢？

怎么解决由这种**热点行更新**导致的性能问题呢？

出现这种问题的原因本质上是**因为死锁检测耗费了大量的CPU资源**。

解决方法：

1. 若确保业务不会出现死锁，可**临时关闭死锁探测**。但存在风险，关闭死锁探测意味着可能出现大量的时，严重影响业务。
2. **控制并发度**。可使用中间件，实现在服务端控制线程的并发数量，使得InnoDB内部不需要大量的死锁检测工作。
3. 调整逻辑代码，减少行锁冲突

# 死锁和死锁检测

当并发系统中不同线程出现**循环资源依赖**，涉及的线程都在**等待**别的线程释放资源时，就会导致这几个线程进入**无限等待的状态**，称为死锁。

![img](MySQL笔记图片.assets/死锁.jpg)

如图，假设t表主键为id,事务A在等待事务B释放Id=2的行锁，而事务B在等待事务A释放Id=1的行锁，这种互相等待对方释放资源的状态，就是死锁状态。

如何解决？两种策略：

- 第一种：直接进入等待，直到超时。超时时间可通过参数innodb_lock_wait_timeout来设置，默认值是50s。
- 第二种：发起死锁探测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务可以执行。将参数innodb_deadlock_detect设置成on，表示开启死锁探测。

InnoDB中死锁的超时等待参数：innodb_lock_timeout的默认值是50s，这个长时间等待对于业务来说是无法接受的，假若设置其值为1s，出现死锁确实可以快速解开，但若不是死锁，只是简单的锁等待的话，这种策略是行不通的。

因此，我们往往使用**死锁探测**来解决。而且，innodb_deadlock_detect本身的默认值是on，其发现死锁时，可以快速处理，但有额外的负担。

死锁探测使得MySQ有额外的负担，它会对每个新来的被堵住的线程，都要判断会不会由于自己的加入而导致死锁，**这时的时间复杂度是O(n)**。

假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务。



# 思考题

若你要删除一张表中前10000行数据，有以下三种方法：

1. 直接执行 delete from T limit 10000;
2. 在一个连接中循环执行 20 次 delete from T limit 500;
3. 在 20 个连接中同时执行 delete from T limit 500。

你会选择哪一种方法呢？为什么呢？

选用第二种方式。

分析：

第一种方式（即：直接执行 delete from T limit 10000）里面，单个语句占用时间长，锁的时间也比较长；而且大事务还会导致主从延迟。

第三种方式（即：在 20 个连接中同时执行 delete from T limit 500），会人为造成锁冲突。













